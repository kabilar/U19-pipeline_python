{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the workflow structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives a brief overview of the workflow structure and introduce some useful DataJoint tools to facilitate the exploration.\n",
    "+ DataJoint needs to be pre-configured before running this notebook, if you haven't set up the configuration, refer to notebook [00-Set-up-configuration](00-Set-up-configuration.ipynb).\n",
    "+ If you are familar with DataJoint and the workflow structure, proceed to the next notebook [02-process-ephys-workflow](02-process-ephys-workflow.ipynb) directly to run the workflow.\n",
    "+ For a more thorough introduction of DataJoint functionings, please visit our [datajoint tutorial site](https://playground.datajoint.io) or [tutorials for BrainCogs U19 team](../tutorials/202103)\n",
    "+ The current workflow is composed of multiple database schemas, each of them corresponds to a module within the database.\n",
    "+ Some of the schemas and tables are from `u19_pipeline`, and the ephys related schemas are from the [DataJoint Array Ephys Element](https://github.com/datajoint/element-array-ephys) installed in `u19_pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "dj.config['database.host'] = 'datajoint00.pni.princeton.edu'\n",
    "dj.config['database.user'] = '<username>'\n",
    "dj.config['database.password'] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the schemas and tables in this workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = dj.create_virtual_module('subject', 'u19_subject')\n",
    "acquisition = dj.create_virtual_module('acquisition', 'u19_acquisition')\n",
    "ephys = dj.create_virtual_module('ephys', 'u19_ephys')\n",
    "probe_element = dj.create_virtual_module('probe_element', 'u19_probe_element')\n",
    "ephys_element = dj.create_virtual_module('ephys_element', 'u19_ephys_element')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developer setup\n",
    "+ Connect to the database using `dj_local_conf.json` file or use the `U19-pipeline_python/notebooks/00-Datajoint-configuration.ipynb` notebook.\n",
    "+ Once the `dj_local_conf.json` is declared, to load the local configuration we will change the directory to the package root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the schemas and tables in this workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from u19_pipeline import subject, acquisition, ephys\n",
    "from u19_pipeline.ephys import probe_element, ephys_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schemas and tables\n",
    "\n",
    "+ A `schema` is a container/folder that houses `tables`\n",
    "\n",
    "+ DataJoint's schema/table convention\n",
    "\n",
    "     | Python      | Database          | example\n",
    "     | ----------- | ------------------|------------\n",
    "     | Module      | Schema            | `ephys`\n",
    "     | Class       | Table             | `EphysRecording`\n",
    "\n",
    "\n",
    "+ Each module contains a schema object that enables interaction with the schema in the database.\n",
    "+ The module `ephys` is the native \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_element.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Each module imported above corresponds to one schema inside the database. For example, `ephys` corresponds to `neuro_ephys` schema in the database."
   },
   "outputs": [],
   "source": [
    "ephys_element.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The table classes in the module corresponds to a table in the schema in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Each datajoint table class inside the module corresponds to a table inside the schema. For example, the class `ephys.EphysRecording` correponds to the table `_ephys_recording` in the schema `neuro_ephys` in the database."
   },
   "outputs": [],
   "source": [
    "# preview table columns and contents in a table\n",
    "ephys_element.EphysRecording()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "The first time importing the modules, empty schemas and tables will be created in the database."
   },
   "source": [
    "+ By importing the modules for the first time, the schemas and tables will be created inside the database.\n",
    "+ Once created, importing modules will not create schemas and tables again, but the existing schemas/tables can be accessed and manipulated by the modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration of Ephys Workflow\n",
    "+ For the purpose of this notebook, we have already run the workflow for a few data sets. As a result, the processed data are already in the database and ready to be explored. \n",
    "\n",
    "### Generate a raster plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units, unit_spiketimes = (ephys_element.CuratedClustering.Unit & 'subject_fullname=\"ms81_M005\"' & 'session_date=\"2021-05-05\"' & 'insertion_number = 0' & 'curation_id=1' & 'cluster_quality_label = \"good\"').fetch('unit', 'spike_times')\n",
    "\n",
    "x = np.hstack(unit_spiketimes)\n",
    "y = np.hstack([np.full_like(s, u) for u, s in zip(units, unit_spiketimes)])\n",
    "\n",
    "fig, ax = pyplot.subplots(1, 1, figsize=(32, 16))\n",
    "ax.plot(x, y, '|')\n",
    "ax.set_xlabel('Time (s)');\n",
    "ax.set_ylabel('Unit');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot waveform of a unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_key = (ephys_element.CuratedClustering.Unit & 'subject_fullname=\"ms81_M005\"' & 'session_date=\"2021-05-05\"' & 'insertion_number = 0' & 'curation_id=1' & 'unit = 26').fetch1('KEY')\n",
    "\n",
    "ephys_element.CuratedClustering.Unit * ephys_element.WaveformSet.Waveform & unit_key\n",
    "\n",
    "unit_data = (ephys_element.CuratedClustering.Unit * ephys_element.WaveformSet.PeakWaveform & unit_key).fetch1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = (ephys_element.EphysRecording & 'subject_fullname=\"ms81_M005\"' & 'session_date=\"2021-05-05\"' & 'insertion_number = 0').fetch1('sampling_rate')/1000 # in kHz\n",
    "\n",
    "pyplot.plot(np.r_[:unit_data['peak_electrode_waveform'].size] * 1/sampling_rate, unit_data['peak_electrode_waveform'])\n",
    "pyplot.xlabel('Time (ms)')\n",
    "pyplot.ylabel(r'Voltage ($\\mu$V)')\n",
    "pyplot.title(\"Waveform of a Unit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataJoint tools to explore schemas and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "The schemas and tables will not be re-created when importing modules if they have existed."
   },
   "source": [
    "+ `dj.list_schemas()`: list all schemas a user has access to in the current database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "`dj.list_schemas()`: list all schemas a user could access."
   },
   "outputs": [],
   "source": [
    "dj.list_schemas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `dj.Diagram()`: plot tables and dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "`dj.Diagram()`: plot tables and dependencies"
   },
   "outputs": [],
   "source": [
    "# plot diagram for all tables in a schema\n",
    "dj.Diagram(ephys_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table tiers**\n",
    "\n",
    "+ Green box - Manual table\n",
    "     + Manually inserted table, expect new entries daily, e.g. Subject, ProbeInsertion.  \n",
    "\n",
    "+ Gray box - Lookup table\n",
    "     + Pre inserted table, commonly used for general facts or parameters. eg. Strain, ClusteringMethod, ClusteringParamSet.  \n",
    "\n",
    "+ Blue oval - Imported table\n",
    "     + Auto-processing table, the processing depends on the importing of external files. e.g. process of Clustering requires output files from kilosort2.  \n",
    "\n",
    "+ Red circle - Computed table\n",
    "     + Auto-processing table, the processing does not depend on files external to the database, commonly used for data analyses.     \n",
    "\n",
    "+ Plain text - Part table\n",
    "     + As an appendix to the master table, all the part entries of a given master entry represent a intact set of the master entry. e.g. Unit of a CuratedClustering.\n",
    "\n",
    "**Dependencies**\n",
    "\n",
    "+ Thick solid line - One-to-one primary\n",
    "     + Share the exact same primary key, meaning the child table inherits all the primary key fields from the parent table as its own primary key.\n",
    "\n",
    "+ Thin solid line - One-to-many primary\n",
    "     + Inherit the primary key from the parent table, but have additional field(s) as part of the primary key as well\n",
    "\n",
    "+ Dashed line - Secondary dependency\n",
    "     + The child table inherits the primary key fields from parent table as its own secondary attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "`dj.Diagram()`: plot the diagram of the tables and dependencies. It could be used to plot tables in a schema or selected tables."
   },
   "outputs": [],
   "source": [
    "# plot diagram of tables in multiple schemas\n",
    "dj.Diagram(subject) + dj.Diagram(acquisition) + dj.Diagram(ephys) + dj.Diagram(ephys_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagram of selected tables and schemas\n",
    "dj.Diagram(subject.Subject) + dj.Diagram(acquisition.Session) + dj.Diagram(ephys) + dj.Diagram(ephys_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagram with 1 additional level of dependency downstream\n",
    "dj.Diagram(subject.Subject) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagram with 2 additional levels of dependency upstream\n",
    "dj.Diagram(ephys_element.EphysRecording) - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "`heading`:"
   },
   "source": [
    "+ `describe()`: show table definition with foreign key references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_element.EphysRecording.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `heading`: show attribute definitions regardless of foreign key references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "`heading`: show table attributes regardless of foreign key references."
   },
   "outputs": [],
   "source": [
    "ephys_element.EphysRecording.heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "probe"
   },
   "source": [
    "# Major tables for the ephys workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject, session, and ephys session\n",
    "dj.Diagram(subject.Subject) + dj.Diagram(acquisition.Session) + dj.Diagram(ephys.EphysSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "[subject](https://github.com/datajoint/element-animal): contains the basic information of subject, including Strain, Line, Subject, Zygosity, and SubjectDeath information."
   },
   "outputs": [],
   "source": [
    "subject.Subject.describe();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition.SessionStarted.describe();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition.Session.describe();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the data directory ephys data\n",
    "ephys.EphysSession.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [`ephys_element`](https://github.com/datajoint/element-array-ephys): Neuropixel based probe and ephys information. Check [this link](https://github.com/datajoint/element-array-ephys/tree/main/element_array_ephys) for definitions of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "[probe and ephys](https://github.com/datajoint/element-array-ephys): Neuropixel based probe and ephys tables"
   },
   "outputs": [],
   "source": [
    "dj.Diagram(probe_element) + dj.Diagram(ephys_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and next step\n",
    "\n",
    "+ This notebook introduced the overall structures of the schemas and tables in the workflow and relevant tools to explore the schema structure and table definitions.\n",
    "\n",
    "+ In the next notebook [02-process-ephys-workflow](02-process-ephys-workflow.ipynb), we will further introduce the detailed steps running through the pipeline and table contents accordingly."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
